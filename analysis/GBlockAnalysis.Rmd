---
title: "Analysis"
author: "Brian Palmer"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(BSgenome)
setwd("/home/bpalmer/Documents/GitHub/gblock-detection/analysis")
```

```{r}
spikein_counts_df <- read_delim("~/Documents/GitHub/gblock-detection/spikeins_xi_results/stats/spikeins_data.txt") %>%
  group_by(SampleID) %>%
  # Remove unnecessary parts and extract Well and SDSI
  mutate(
    Well = str_extract(SampleID, "(^.*-[A-Z][0-9]+)-", group = 1),
    Well = str_replace(Well, "(SDSI[0-9]-|negcontrol-|original-|SDSI[0-9]_[0-9]-|SDSI[0-9]_[0-9]_[0-9]-|SDSI[0-9],[0-9]-|SDSI[0-9],[0-9],[0-9]-)", ""),
    SDSI = str_extract(SampleID, "SDSI[0-9](_[0-9])*"),
    SDSI = str_replace_all(SDSI, "_", ","), # Convert underscores to commas for separation
    Spikeins = str_split(SDSI, ",") # Split into individual Spikeins
  ) %>%
  unnest(Spikeins) %>%  # Create separate rows for each Spikein
  mutate(
    Spikeins = ifelse(grepl("^[0-9]+$", Spikeins), paste0("SDSI", Spikeins), Spikeins) # Add "SDSI" prefix to numeric Spikeins
  ) %>%
  ungroup()

# spikein_counts_df <- read_delim("~/Documents/GitHub/gblock-detection/spikeins_xi_results/stats/spikeins_data.txt")
# # print(spikein_counts_df, n = 100)

pool5 <- read.table("pool_5.txt", header = F) %>% pull()

species_loci = c('PmUG01_12_v1-1397996-1398245-1AB','PocGH01_12_v1-1106456-1106697-1AB','PvP01_12_v1-1184983-1185208-1AB')
amplicons_df <- read_delim("~/Documents/GitHub/gblock-detection/spikeins_xi_results/amplicon_coverage.txt") %>%
  # mutate(SampleID = str_replace_all(SampleID, "_S[0-9]+_L005$", "")) %>% # results ix
  # mutate(Well = str_extract(SampleID, "(^[A-Z][0-9]+)-", group = 1)) %>% # results ix
  mutate(Well = str_extract(SampleID, "(^.*-[A-Z][0-9]+)-", group = 1)) %>% # results xi
  mutate(Well = str_replace(Well, "(SDSI[0-9]-|negcontrol-|original-|SDSI[0-9]_[0-9]-|SDSI[0-9]_[0-9]_[0-9]-)", "")) %>% # resultx xi
  filter((grepl("-1A$", Locus) | Locus %in% pool5) & !(Locus %in% species_loci)) # results xi

metadata_df <-  read_csv("~/Documents/GitHub/gblock-detection/spikein_xi_metadata.csv")
dilutions_df <- metadata_df %>%
  select(
    SampleID = `Sample name for sequencing`,
    Density = `parasite_density`
  ) %>%
  mutate(
    SIDilution = ifelse(Density > 0 & !grepl("original", SampleID), "1:10", "0"),
    SIPrimerDilution = ifelse(Density > 0 & !grepl("original", SampleID), "1:250", "0"),
    # Well = str_extract(SampleID, "(^[A-Z][0-9]+)-", group = 1),
    Well = str_extract(SampleID, "(^.*-[A-Z][0-9]+)-", group = 1), # results xi
    Well = str_replace(Well, "(SDSI[0-9]-|negcontrol-|original-|SDSI[0-9]_[0-9]-|SDSI[0-9]_[0-9]_[0-9]-|SDSI[0-9],[0-9]-|SDSI[0-9],[0-9],[0-9]-)", ""), # resultx xi
    # Density = factor(Density, levels = c("H2O", "100", "1000"))
  )

# read the sequences from the reference genome (already extracted into a fasta file)
gblocks_df <- read_csv("~/Documents/GitHub/gblock-detection/resources/gblocks.csv")
gblock_sequence <- gblocks_df %>%
  mutate(GBlockSequence = str_remove(GBlockSequence, "^ACAGTTCTCCTTCTTAGCTTCGTGAGAAC")) %>%
  mutate(GBlockSequence = str_remove(GBlockSequence, "CACATCATGTAGTAGACGACCAAGACAGT$")) %>%
  mutate(GBlockSequence = substr(GBlockSequence, 2, nchar(GBlockSequence) - 1)) %>% # Remove 1st and last base
  
  # Extract the numeric part from SpikeinID and store it in 'number'
  mutate(number = str_extract(SpikeinID, "[0-9]+")) %>% 
  
  # Optionally modify the SpikeinID, if needed
  mutate(SpikeinID = sprintf("SDSI%d", as.numeric(number)))
  # pull(GBlockSequence)

# The above we're joined previously to create this csv. The output
# was saved. The script from before was lost due to CPU freeze.
# joined_df <- read.csv("/home/bpalmer/Documents/SpikeIns-10_26_2023/metadata/output.csv")

# spikeins_df <- read_table("~/Documents/GitHub/gblock-detection/spikeins_xi_results/stats/spikeins_data.txt") %>%
#   # mutate(SampleID = str_replace_all(SampleID, "_S[0-9]+_L005$", "")) %>%
#   mutate(
#     Well = str_extract(SampleID, "(^.*-[A-Z][0-9]+)-", group = 1), # results xi
#     Well = str_replace(Well, "(SDSI[0-9]-|negcontrol-|original-|SDSI[0-9]_[0-9]-|SDSI[0-9]_[0-9]_[0-9]-|SDSI[0-9],[0-9]-|SDSI[0-9],[0-9],[0-9]-)", "")) # resultx xi
# 
# write.csv(spikeins_df, file = "spikein_input.csv", quote = F, row.names = F)





# Function to compute Spikein Summary with spikein count in GBlockSequence
compute_spikein_summary <- function(spikein_counts_df, gblock_sequence, dilutions_df) {
  
  # Join gblock_sequence data with the spikein counts data on Spikeins
  spikin_perfect_match_df <- spikein_counts_df %>%
    left_join(gblock_sequence, by = c("Spikeins" = "SpikeinID")) %>%
    
    # For each sample, calculate the exact reads matching a GBlockSequence
    rowwise() %>%
    mutate(
      SpikeinReadsExact = sum(Spikein == GBlockSequence), # Detect if the spikein matches the GBlockSequence

      # SpikeinReadsExact = ifelse(str_detect(Spikein, GBlockSequence), Reads, 0) # Detect if the spikein matches the GBlockSequence
    ) %>%
    ungroup() %>%
    
    # Group by relevant fields and sum the exact match reads for each sample
    group_by(SampleID, Well, Spikeins) %>%
    summarise(SpikeinReadsExact = sum(SpikeinReadsExact, na.rm = TRUE), .groups = 'drop') %>%
    
    # Arrange by the highest number of reads
    arrange(desc(SpikeinReadsExact))
    
  # Create a dataframe for sequences that do not match any gblock sequence
  spikein_no_match_df <- spikein_counts_df %>%
    group_by(Well) %>%
    filter(!str_detect(Spikein, paste(gblock_sequence$GBlockSequence, collapse = "|"))) %>%
    summarise(UnexpectedSeqCount = sum(Reads), .groups = 'drop')
  
  # Join data and calculate the proportion of perfect matches
  spikin_perfect_match_df %>%
    left_join(spikein_no_match_df, by = "Well") %>%
    left_join(dilutions_df %>% select(-SampleID), by = "Well") %>%
    distinct(SampleID, SIDilution, SIPrimerDilution, Reads, UnexpectedSeqCount) %>%
    mutate(ProportionPerfectMatch = Reads / (Reads + UnexpectedSeqCount))
}


# Usage example
spikein_summary_df <- compute_spikein_summary(spikein_counts_df, gblock_sequence, dilutions_df)

# spikein_summary_df[spikein_summary_df$SampleID == "BO1_110SI_110PR_042024_SI_IX", ]$SampleID = "B01_110SI_110PR_042024_SI_IX"
# spikein_summary_df[is.na(spikein_summary_df$UnexpectedSeqCount), ]$UnexpectedSeqCount = 0
# spikein_summary_df[is.na(spikein_summary_df$ProportionPerfectMatch), ]$ProportionPerfectMatch = 0
spikein_summary_df <- spikein_summary_df %>%
  filter(spikein_summary_df$SIDilution != "" & SIPrimerDilution != "") 

write.csv(spikein_summary_df, file = "spikein_summary.csv", quote = F, row.names = F)

# Join gblock_sequence data with the spikein counts data on Spikeins
spikin_perfect_match_df <- spikein_counts_df %>%
  left_join(gblock_sequence, by = c("Spikeins" = "SpikeinID")) %>%
  
  # For each sample, calculate the exact reads matching a GBlockSequence
  rowwise() %>%
  mutate(
    SpikeinReadsExact = ifelse(str_detect(GBlockSequence, Spikein), Reads, 0) # Detect if the spikein matches the GBlockSequence
  ) %>%
  ungroup() %>%
  
  # Group by relevant fields and sum the exact match reads for each sample
  group_by(SampleID, Well, Spikeins) %>%
  summarise(SpikeinReadsExact = sum(SpikeinReadsExact, na.rm = TRUE), .groups = 'drop') %>%
  
  # Arrange by the highest number of reads
  arrange(desc(SpikeinReadsExact))
```


```{r}
library(ggbeeswarm)
library(patchwork)
joined_df <- amplicons_df %>%
  left_join(spikin_perfect_match_df %>% select(-SampleID) %>% dplyr::rename(SpikinReads = SpikeinReadsExact), by = c("Well")) %>%
  left_join(dilutions_df %>% select(-SampleID), by = c("Well")) %>%
  mutate(SpikinReads = replace_na(SpikinReads, 0)) %>%
  mutate(Spikeins = replace_na(Spikeins, "None"))

# joined_df[joined_df$SampleID == "BO1_110SI_110PR_042024_SI_IX", ]$SampleID = "B01_110SI_110PR_042024_SI_IX"
# joined_df[joined_df$SampleID == "B01_110SI_110PR_042024_SI_IX", ]$Well = "B01"
# joined_df[is.na(joined_df)] <- 0

# Function to sort dilutions by increasing dilution
factorize_dilutions <- function(dilutions) {
  convert_dilution_to_numeric <- function(dilution, delim = ':') {
    if (grepl(delim, dilution)) {
      parts <- strsplit(dilution, delim)[[1]]
      return(as.numeric(parts[2]))
    } else if (dilution == "0") {
      return(0)
    } else {
      stop("Could not handle dilution during factorization!")
    }
  }
  numeric_dilutions <- sapply(dilutions, convert_dilution_to_numeric)
  sorted_dilutions <- dilutions[order(numeric_dilutions)]
  factor(dilutions, levels = unique(sorted_dilutions))
}

joined_df$SIDilution <- factorize_dilutions(joined_df$SIDilution)
joined_df$SIPrimerDilution <- factorize_dilutions(joined_df$SIPrimerDilution)

# Create the Interaction without appending "(Pos)" or "(Neg)"
joined_df <- joined_df %>%
  mutate(Interaction = interaction(SIDilution, SIPrimerDilution, sep = " x ", lex.order = TRUE)) %>%
  mutate(ControlType = if_else(grepl("(negative|Neg|negcontrol)", SampleID), "Neg", "Pos"))
  # mutate(ControlType = if_else(grepl("Neg", SampleID), "Neg", "Pos"))

# Save the levels and reorder after appending "(Pos)" and "(Neg)"
interaction_levels <- levels(joined_df$Interaction)
interaction_levels_pos <- paste0(interaction_levels, " (Pos)")
interaction_levels_neg <- paste0(interaction_levels, " (Neg)")

# Apply the labels to the Interaction column
joined_df <- joined_df %>%
  mutate(Interaction = sprintf("%s (%s)", Interaction, ControlType))

# Combine the levels and set them to the factor
combined_levels <- c(interaction_levels_pos, interaction_levels_neg)
joined_df$Interaction <- factor(joined_df$Interaction, levels = combined_levels)

```

## Read correlation plot

### Sample Level correlation

```{r}
# Summing Reads and SpikinReads by Well
well_sum_df <- joined_df %>%
  filter(Spikeins != "None") %>%
  group_by(Well) %>%
  reframe(
    TotalReads = mean(Reads, na.rm = TRUE),
    TotalSpikinReads = mean(SpikinReads, na.rm = TRUE)
  )

hist(well_sum_df$TotalReads)
hist(well_sum_df$TotalSpikinReads)

# Calculate correlation
well_correlation <- cor(well_sum_df$TotalReads, well_sum_df$TotalSpikinReads, method = "pearson")

# Correlation plot for Well
well_correlation_plot <- ggplot(well_sum_df, aes(x = TotalReads, y = TotalSpikinReads)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(
    title = paste("Correlation Between SpikinReads and Reads by Well: p =", round(well_correlation, 2)),
    x = "Average Reads by Well",
    y = "Average SpikinReads by Well"
  ) +
  theme_minimal()

# Print the plot
print(well_correlation_plot)

```

## Read vs spikin jitter plot

```{r}
# Continue with the rest of the data manipulation
joined_df <- joined_df %>%
  mutate(Reads = log1p(Reads), SpikinReads = log1p(SpikinReads)) %>%
  group_by(Interaction) %>%
  mutate(MeanSpikin = mean(SpikinReads)) %>%
  mutate(
    MeanSpikin = replace_na(MeanSpikin, 0),
    SpikinReads = replace_na(SpikinReads, 0)) %>%
  ungroup()
  
replicate_df <- joined_df %>% 
  distinct(SampleID, Interaction) %>%
  group_by(Interaction) %>%
  mutate(Replicate = as.factor(row_number()))

joined_df <- joined_df %>%
  left_join(replicate_df, by = c("SampleID", "Interaction")) %>%
  mutate(Well_Label = paste(Well, ControlType, sep = " - ")) # Combine Well and ControlType

# abundances_plot <- ggplot(joined_df, aes(x = Interaction, y = Reads, fill = Replicate)) +
#   geom_quasirandom(dodge.width = 0.8, colour = "#134e90") +
#   theme_minimal() +
#   labs(
#     title = NULL,
#     x = "Interaction Groups (GBlock x Primer)",
#     y = "Reads (log1p)",
#     fill = element_blank(), 
#     subtitle = NULL
#   ) +
#   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
#   
#   # Color spike-in points by Spikeins
#   geom_point(aes(x = Interaction, y = SpikinReads, color = Spikeins), size = 2, shape = 8) +
#   
#   # Remove the 'fill' legend related to Replicate
#   guides(fill = "none") +  # Hide the fill legend
#   
#   # Customize the legend for Spikeins
#   guides(color = guide_legend(title = "Spikeins", override.aes = list(size = 4))) +
#   
#   # Other settings
#   theme(legend.position = "right") +
#   facet_wrap(~ Well) +
#   labs(
#     title = "Spike-in and Amplicon Read Counts by Interaction Group across Parasitemia Levels", 
#     subtitle = "Spike-in points colored by Spikeins"
#   )
# 
# print(abundances_plot)

# Plot for the first interaction group with Well and ControlType on x-axis
interaction_group1_plot <- ggplot(joined_df %>% filter(Interaction == "0 x 0 (Pos)"), aes(x = Well_Label, y = Reads, fill = Replicate)) +
  geom_jitter(width = 0.2, height = 0.1, colour = "#134e90") +  # Add jitter for better visualization
  theme_minimal() +
  labs(
    title = "Spike-in and Amplicon Read Counts for 0 x 0 (Pos)",
    x = "Well - Control Type",
    y = "Reads (log1p)",
    fill = element_blank(), 
    subtitle = NULL
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  
  # Color spike-in points by Spikeins
  geom_point(aes(x = Well_Label, y = SpikinReads, color = Spikeins), size = 3, shape = 8) +  # Adjust size and shape
  
  # Remove the 'fill' legend related to Replicate
  guides(fill = "none") +  # Hide the fill legend
  
  # Customize the legend for Spikeins
  guides(color = guide_legend(title = "Spikeins", override.aes = list(size = 4))) +
  
  # Other settings
  theme(legend.position = "right")

# Plot for the second interaction group with Well and ControlType on x-axis
interaction_group2_plot <- ggplot(joined_df %>% filter(Interaction == "1:10 x 1:250 (Pos)"), aes(x = Well_Label, y = Reads, fill = Replicate)) +
  geom_jitter(width = 0.2, height = 0.1, colour = "#134e90") +  # Add jitter for better visualization
  theme_minimal() +
  labs(
    title = "Spike-in and Amplicon Read Counts for 1:10 x 1:250 (Pos)",
    x = "Well - Control Type",
    y = "Reads (log1p)",
    fill = element_blank(), 
    subtitle = NULL
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  
  # Color spike-in points by Spikeins
  geom_point(aes(x = Well_Label, y = SpikinReads, color = Spikeins), size = 3, shape = 8) +  # Adjust size and shape
  
  # Remove the 'fill' legend related to Replicate
  guides(fill = "none") +  # Hide the fill legend
  
  # Customize the legend for Spikeins
  guides(color = guide_legend(title = "Spikeins", override.aes = list(size = 4))) +
  
  # Other settings
  theme(legend.position = "right")

# Print both plots
print(interaction_group1_plot)
print(interaction_group2_plot)

x <- joined_df %>% 
  group_by(Interaction, Well) %>%
  reframe(Reads = sum(Reads))

print(x)  

output <- joined_df %>%
  distinct(SampleID, SIDilution, SIPrimerDilution, ControlType) %>%
  left_join(spikin_perfect_match_df %>% select(SampleID, ExactMatchReads = SpikeinReadsExact, UnexpectedSeqCount), by = c("SampleID")) %>%
  mutate(ProportionCorrect = ExactMatchReads / (ExactMatchReads + UnexpectedSeqCount)) %>%
  arrange(desc(ProportionCorrect))

output[is.na(output)] <- 0
write.csv(output, file = "spikin_counts.csv")     

# spikein_summary_df$Interaction <- factor(spikein_summary_df$Interaction, levels = combined_levels)

library(scales) # For the percent_format() function
spikein_summary_df <- spikein_summary_df %>%
  mutate(Interaction = interaction(SIDilution, SIPrimerDilution, sep = " x ", lex.order = TRUE)) %>%
  mutate(ControlType = if_else(grepl("(negative|Neg|negcontrol)", SampleID), "Neg", "Pos"))
  
# Save the levels and reorder after appending "(Pos)" and "(Neg)"
interaction_levels <- levels(spikein_summary_df$Interaction)
interaction_levels_pos <- paste0(interaction_levels, " (Pos)")
interaction_levels_neg <- paste0(interaction_levels, " (Neg)")

# Apply the labels to the Interaction column
spikein_summary_df <- spikein_summary_df %>%
  mutate(Interaction = sprintf("%s (%s)", Interaction, ControlType))

# Combine the levels and set them to the factor
combined_levels <- c(interaction_levels_pos, interaction_levels_neg)
spikein_summary_df$Interaction <- factor(spikein_summary_df$Interaction, levels = combined_levels)

# Calculate the total reads for each sample
spikein_summary_df <- spikein_summary_df %>%
  dplyr::mutate(TotalReads = Reads + UnexpectedSeqCount) %>%
  dplyr::rename(PerfectMatchCount = Reads)

# Calculate summary statistics for the plot
summary_stats <- spikein_summary_df %>%
  group_by(Interaction) %>%
  summarise(TotalReads = sum(TotalReads))

# Plot using ggplot2
ggplot(spikein_summary_df, aes(x = Interaction, y = ProportionPerfectMatch)) +
  geom_boxplot() +
  scale_y_continuous(labels = percent_format(), limits=c(0,1)) +
  theme_minimal() +
  labs(title = "Proportion of Spike-ins that Matched SDSI01 Exactly",
       x = "Interaction Groups (GBlock x Primer)",
       y = "Proportion Exact Match (%)",
       fill = element_blank()
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  geom_text(data = summary_stats, aes(x = Interaction, y = 1.05, label = paste0("Total Reads: ", comma(TotalReads))),
            color = "blue", size = 3, angle = 90, vjust = 0.5, hjust = 1)
```

## Look at read correlation


```{r}
# Convert necessary columns to factors
joined_df$SIDilution <- as.factor(joined_df$SIDilution)
joined_df$SIPrimerDilution <- as.factor(joined_df$SIPrimerDilution)
joined_df$Locus <- as.factor(joined_df$Locus)
```

## Upfront EDA

### Look at the distribution of reads per amplicon

We are getting reads pretty consistently across the primer dilutions in the different spikein groups. The next step would be to look at the amplicons closely to see if there are fluctuations across groups. 

Looks like the spikeins are also appearing, particularly when the primer dilution group approaches 100.

## Look at the different groups to see if we're getting odd allele counts

```{r}
alleledata_df <- read.table("mad4hatter-runs/resultsxi/allele_data.txt", sep = "\t", header = TRUE) %>%
  mutate(
   Well = str_extract(SampleID, "(^.*-[A-Z][0-9]+)-", group = 1),
   Well = str_replace(Well, "(SDSI[0-9]-|negcontrol-|original-|SDSI[0-9]_[0-9]-|SDSI[0-9]_[0-9]_[0-9]-|SDSI[0-9],[0-9]-|SDSI[0-9],[0-9],[0-9]-)", "")
  ) %>%
  select(-SampleID)

unfiltered_alleledata_joined_df <- joined_df %>%
  select(Well, Locus, SpikinReads, SIDilution,SIPrimerDilution, Interaction, ControlType, MeanSpikin, Replicate, Density) %>%
  left_join(alleledata_df, by = join_by(Well, Locus)) %>%
  mutate(Well = as.factor(Well))

# Filter to keep only the allele with the highest read count per locus per well
top_allele_per_locus_well <- unfiltered_alleledata_joined_df %>%
  group_by(Well, Locus) %>%
  slice_max(order_by = Reads, n = 1, with_ties = FALSE) %>%
  ungroup()

# Join the original data frame with the filtered top alleles data frame
alleledata_joined_df <- unfiltered_alleledata_joined_df %>%
  # Perform a semi join, which filters rows in the first table to those that have matches in the second table
  semi_join(top_allele_per_locus_well, by = c("Well", "Locus", "ASV", "Reads"))

alleledata_joined_df[is.na(alleledata_joined_df$Reads), ]$Reads <- 0
alleledata_joined_df <- alleledata_joined_df %>%
  filter(Reads == 0 | Reads >= 10)


```


```{r}
library(dplyr)
library(purrr)
library(patchwork)
library(viridis)

# Function to calculate TP, FP, FN
calculate_metrics_with_pseudocigar <- function(control, experiment) {
  
  results_list <- list()
  missing_asvs <- list()

  unique_experiment_wells <- unique(experiment$Well)
  
  for (exp_well in unique_experiment_wells) {
      experiment_well_df <- filter(experiment, Well == exp_well)
  
      # Join with control
      full_data <- full_join(control, experiment_well_df, by = c("Locus", "PseudoCIGAR"), suffix = c("_ctrl", "_exp"))
      full_data[is.na(full_data$Reads_ctrl),]$Reads_ctrl <- 0
      full_data[is.na(full_data$Reads_exp),]$Reads_exp <- 0
      
      stats_df <- full_data %>%
        group_by(Locus, PseudoCIGAR) %>%
        reframe(
          FP = sum(!is.na(Well_exp) & is.na(Well_ctrl)),
          FN = sum(is.na(Well_exp) & !is.na(Well_ctrl)),
          TP = sum(!is.na(Well_exp) & !is.na(Well_ctrl))
        ) %>%
        mutate(Well_exp := !! exp_well)

      results_list[[exp_well]] <- stats_df
  
      # Record missing ASVs
      missing_data <- full_data %>%
        filter(is.na(Well_exp) & !is.na(Well_ctrl)) %>%
        select(Locus, PseudoCIGAR, Reads_ctrl) %>%
        filter(!is.na(PseudoCIGAR))
      
      missing_data$Well_exp <- exp_well
      missing_asvs[[exp_well]] <- missing_data
  }
  
  stats_final_df <- bind_rows(results_list) %>%
    group_by(Well_exp) %>%
    summarise(
      Precision = sum(TP) / (sum(TP) + sum(FP)),
      Recall = sum(TP) / (sum(TP) + sum(FN)),
      .groups = 'drop'
    )
  
  missing_asvs_df <- bind_rows(missing_asvs) %>%
      group_by(Well_exp) %>%
      nest(Data = c(Locus, PseudoCIGAR, Reads_ctrl))

  # Combine summary metrics with missing ASV details
  final_results_df <- left_join(stats_final_df, missing_asvs_df, by = join_by(Well_exp))
  
  final_results_df
}

# Function to calculate TP, FP, FN
calculate_fn_details <- function(control, experiment) {
  
  unique_experiment_wells <- unique(experiment$Well)
  results_list <- list()
  
  for (exp_well in unique_experiment_wells) {
    
    experiment_well_df <- experiment %>% 
      filter(Well == exp_well)
  
    full_data <- full_join(control, experiment_well_df, by = c("Locus", "PseudoCIGAR"), suffix = c("_ctrl", "_exp"))
    
    full_data[is.na(full_data$Reads_ctrl), ]$Reads_ctrl <- 0
    full_data[is.na(full_data$Reads_exp), ]$Reads_exp <- 0
    
    # Calculate additional details for False Negatives
    fn_details <- full_data %>%
      filter(is.na(Well_exp) & !is.na(Well_ctrl)) %>%
      mutate(Well_exp = exp_well) %>%
      select(Well_exp, Locus, PseudoCIGAR, FN_ASV = ASV_ctrl, FN_Reads = Reads_ctrl)

    results_list[[exp_well]] <- fn_details
  }
  
  fn_final_df <- bind_rows(results_list)

  return (fn_final_df)
}

# Prepare experimental groups dynamically
interaction_types <- setdiff(unique(alleledata_joined_df$Interaction), "0 x 0 (Pos)")
density_levels <- unique(alleledata_joined_df$Density)
# results_list <- list()
results_list_with_pseudocigar <- list()
fn_details <- list()

# Iterate over each interaction type to calculate metrics
for (density in density_levels) {
  for (interaction in interaction_types) {
    
    cat("Processing interaction:", interaction, "Density:", density, "\n")
    
    experiment_data <- alleledata_joined_df %>%
      filter(Interaction == interaction & Density == density) %>%
      select(Well = Well, Locus, ASV, PseudoCIGAR, Reads)
    
    if (nrow(experiment_data) == 0) {
      cat("No data for interaction:", interaction, "Density:", density, "\n")
      next
    }
    
    # Prepare the control group data
    control_data <- alleledata_joined_df %>%
      filter(Interaction == "0 x 0 (Pos)" & Density == density) %>%
      select(Well = Well, Locus, ASV, PseudoCIGAR, Reads)
    
    id <- paste(interaction, density, sep = ";")
    
    cat("Calculating metrics for interaction:", interaction, "Density:", density, "\n")
    cat("Id:", id, "\n")

    results <- calculate_metrics_with_pseudocigar(control_data, experiment_data)
    
    print(results)
    
    results$Interaction <- interaction
    results$Density <- density
    results_list_with_pseudocigar[[id]] <- results
    
    results <- calculate_fn_details(control_data, experiment_data)
    results$Interaction <- interaction
    results$Density <- density
    fn_details[[id]] <- results
  }
}

# Combine all results into a single dataframe
# final_results <- bind_rows(results_list)
final_results_with_pseudocigar <- bind_rows(results_list_with_pseudocigar)
final_fn_details <- bind_rows(fn_details)

# Print the final results
# print(final_results)
print(final_results_with_pseudocigar)

interaction_groups_df <- spikein_summary_df %>%
  distinct(Interaction, ControlType)

denisty_df <- dilutions_df %>%
  distinct(Well_exp = Well, Density) %>%
  mutate(Density = ifelse(Density >= 1000, 1000, Density))

# final_results_df <- final_results %>%
#   left_join(interaction_groups_df, by = join_by(Interaction))

final_results_with_pseudocigar_df <- final_results_with_pseudocigar %>%
  mutate(Density = ifelse(Density >= 1000, 1000, Density)) %>%
  # left_join(interaction_groups_df, by = join_by(Interaction)) %>%
  left_join(denisty_df, by = join_by(Well_exp, Density))

# ggplot(final_results_df, aes(x = Precision, y = Recall)) +
#   geom_point(aes(color = Interaction, shape = ControlType), size = 6) +
#   scale_color_discrete(guide = guide_legend(ncol = 2, title = "Interaction")) +
#   scale_shape_discrete(guide = guide_legend(ncol = 2, title = "Control Type"))

final_results_with_pseudocigar_df$Interaction <- factor(final_results_with_pseudocigar_df$Interaction, levels = levels(joined_df$Interaction))

# Number of interaction groups
num_interactions <- length(unique(final_results_with_pseudocigar_df$Interaction))

# Generate colors from viridis
colors <- viridis::viridis_pal(option = "viridis")(num_interactions)

# Create the plot with manually set viridis colors
ggplot(final_results_with_pseudocigar_df, aes(x = Precision, y = Recall)) +
  geom_point(aes(color = Interaction, shape = ControlType), size = 6) +
  scale_color_manual(values = colors, guide = guide_legend(ncol = 2, title = "Interaction")) +  # Manually set viridis colors
  scale_shape_discrete(guide = guide_legend(ncol = 2, title = "Control Type")) +
  labs(
    title = "Precision and Recall of interaction groups compared to 0 x 0 (Pos)"
  ) +
  theme_minimal()

# Assuming final_results_with_pseudocigar_df has columns for Precision, Recall, Interaction, ControlType
reshaped_df <- final_results_with_pseudocigar_df %>%
  pivot_longer(
    cols = c("Precision", "Recall"),  # Columns to make longer
    names_to = "Metric",              # New column for old column names
    values_to = "Value"               # New column for values
  ) %>%
  mutate(Interaction = factor(Interaction, levels = combined_levels))

# View the reshaped dataframe to confirm it looks correct
print(reshaped_df)


# Create the plot with dodged box plots for Precision and Recall
combined_plot <- ggplot(reshaped_df, aes(x = Interaction, y = Value, fill = Metric)) +
  geom_boxplot(position = position_dodge(width = 0.75), alpha = 0.5) +  # Dodge the box plots
  labs(
    x = "Interaction Groups (GBlock x Primer)",
    y = "Metric Value",
    fill = "Metric"  # Label for the legend indicating Metric types
  ) +
  scale_fill_manual(values = c("Precision" = "blue", "Recall" = "red")) +  # Manual color assignment
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "right"
  ) +
  facet_wrap(~ Density) +
  labs(title = "Precision and Recall of interaction groups compared to control group (0 x 0 (Pos))")

print(combined_plot)


final_fn_details <- final_fn_details %>%
  mutate(Interaction = factor(Interaction, levels = combined_levels)) %>%
  mutate(FN_reads_log1p = log10(FN_Reads))

# Plotting FN_Reads across Interaction groups
fn_reads_plot <- ggplot(final_fn_details, aes(x = Interaction, y = FN_reads_log1p)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 1) +  # Display outliers in red
  labs(title = "Distribution of False Negative Reads by Interaction Group",
       x = "Interaction Group",
       y = "False Negative Reads (log10)") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "right"
  )

# Print the plot
print(fn_reads_plot)

```

```{r}
calculate_metrics_with_asv <- function(control, experiment) {
    results_list <- list()
    missing_asvs <- list()
  
    unique_experiment_wells <- unique(experiment$Well)
    
    for (exp_well in unique_experiment_wells) {
        experiment_well_df <- filter(experiment, Well == exp_well)
    
        # Join with control
        full_data <- full_join(control, experiment_well_df, by = c("Locus", "ASV"), suffix = c("_ctrl", "_exp"))
        full_data[is.na(full_data$Reads_ctrl),]$Reads_ctrl <- 0
        full_data[is.na(full_data$Reads_exp),]$Reads_exp <- 0
        
        stats_df <- full_data %>%
          group_by(Locus, ASV) %>%
          reframe(
            FP = sum(!is.na(Well_exp) & is.na(Well_ctrl)),
            FN = sum(is.na(Well_exp) & !is.na(Well_ctrl)),
            TP = sum(!is.na(Well_exp) & !is.na(Well_ctrl))
          ) %>%
          mutate(Well_exp := !! exp_well)

        results_list[[exp_well]] <- stats_df
    
        # Record missing ASVs
        missing_data <- full_data %>%
          filter(is.na(Well_exp) & !is.na(Well_ctrl)) %>%
          select(Locus, ASV, Reads_ctrl) %>%
          filter(!is.na(ASV))
        
        missing_data$Well_exp <- exp_well
        missing_asvs[[exp_well]] <- missing_data
    }
    
    stats_final_df <- bind_rows(results_list) %>%
      group_by(Well_exp) %>%
      summarise(
        Precision = sum(TP) / (sum(TP) + sum(FP)),
        Recall = sum(TP) / (sum(TP) + sum(FN)),
        .groups = 'drop'
      )
    
    missing_asvs_df <- bind_rows(missing_asvs) %>%
        group_by(Well_exp) %>%
        nest(Data = c(Locus, ASV, Reads_ctrl))

    # Combine summary metrics with missing ASV details
    final_results_df <- left_join(stats_final_df, missing_asvs_df, by = join_by(Well_exp))
    
    final_results_df
}

new.truths <- read.csv("../resources/new_truths.csv")

w2_truths_df <- new.truths %>%
  filter(strain == "W2") %>%
  distinct(Locus = locus, ASV = true_allele, Reads = reads) %>%
  mutate(Well = "00") %>%
  filter((grepl("-1A$", Locus) | Locus %in% pool5) & !(Locus %in% species_loci)) %>%
  group_by(Well, Locus) %>%
  slice_max(order_by = Reads, n = 1, with_ties = FALSE) %>%
  ungroup()
  

# Iterate over each interaction type to calculate metrics
experiment_data <- alleledata_joined_df %>%
  filter(Interaction == "0 x 0 (Pos)") %>%
  select(Well = Well, Locus, ASV, PseudoCIGAR, Reads)

results <- calculate_metrics_with_asv(w2_truths_df, experiment_data)
print(results)
```


```{r}
library(dplyr)
library(tidyr)

# Combine all the ASV data into one dataframe
all_asvs <- bind_rows(lapply(results$Data, function(df) {
    transmute(df, Locus, ASV)
}), .id = "Group")

# Count occurrences of each ASV at each locus
asv_counts <- all_asvs %>%
    group_by(Locus, ASV) %>%
    summarise(Count = n_distinct(Group), .groups = 'drop')

print(asv_counts)

write.csv(asv_counts, file = "asvs_missing_from_controls.csv", quote = F, row.names = F)


# ASVs appearing in all groups
asvs_in_all_groups <- filter(asv_counts, Count == n_distinct(all_asvs$Group))

print(asvs_in_all_groups)
```

6 ASVs were found to be missing in all wells. This is partially due to the Ns in the ASVs. Using PseudoCIGARs could be better but we don't have them at the moment for this dataset. From these 6, 2 of then had Ns in them (it's an old dataset.)

3 ASVs were missing from just 1 well each.

1 ASV was missing from 3 wells

Picked B08 to compare the groups of interest.

```{r}
control_data <- alleledata_joined_df %>%
  filter(Interaction == "0 x 0 (Pos)" & Well == "B08") %>%
  select(Well = Well, Locus, ASV, PseudoCIGAR, Reads)

results_list_with_asv <- list()
fn_details <- list()

selected_interactions <- c("1:1 x 1:250 (Pos)", "1:10 x 1:250 (Pos)")

# Iterate over each interaction type to calculate metrics
for (interaction in selected_interactions) {
  experiment_data <- alleledata_joined_df %>%
    filter(Interaction == interaction) %>%
    select(Well = Well, Locus, ASV, PseudoCIGAR, Reads)

  results <- calculate_metrics_with_pseudocigar(control_data, experiment_data)
  results$Interaction <- interaction
  results_list_with_asv[[interaction]] <- results
}

# Combine all results into a single dataframe
# final_results <- bind_rows(results_list)
final_results_with_asv <- bind_rows(results_list_with_asv)

print(final_results_with_asv)

# Combine all the ASV data into one dataframe
all_asvs <- bind_rows(lapply(final_results_with_asv$Data, function(df) {
    transmute(df, Locus, ASV)
}), .id = "Group")

# Count occurrences of each ASV at each locus
asv_counts <- all_asvs %>%
    group_by(Locus, ASV) %>%
    summarise(Count = n_distinct(Group), .groups = 'drop') %>%
  distinct()

print(asv_counts)

# ASVs appearing in all groups
asvs_in_all_groups <- filter(asv_counts, Count == n_distinct(all_asvs$Group))

print(asvs_in_all_groups)

```


In summary:
1. I should probably find a better way to compare control replicates. Comparing against the truth set is working (sorta), there is just clearly ASVs in the truth that are incorrect.
2. Just using a single control replicate as the truth (since they otherwise seem similar in value), used B03 because it had the best recall (albeit, this was against the W2 control that seems bad). 
3. For the groups of interest, we have 0.995 recall or better
